\documentclass[11pt]{article}

\usepackage{paralist}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage[top=0.8in, bottom=0.8in, left=0.8in, right=0.8in]{geometry}
% add other packages here
\usepackage{courier}
\usepackage{graphicx}
\usepackage{array}
\usepackage{wrapfig}

% Put your group number and names in the author field %
\title{\bf Exercise 3\\ Implementing a deliberative Agent}
\author{Group \textnumero76: Simon Honigmann, Arthur Gassner}

% N.B.: The report should not be longer than 3 pages %

\begin{document}
\maketitle

\section{Model Description}

\subsection{Intermediate States}
% Describe the state representation %
For this exercise, the state representation could be simplified compared to the previous because task information is available to the agents. State was represented by the current city of a given agent, a list of all available tasks, and a list of all tasks currently being carried by the agent. A \texttt{State} class was created to conveniently encode this information. \\

In addition to the information included in the vehicle's state, we added some information to the nodes to reduce the complexity of planning algorithms. This information included: the total distance travelled from the root node, the node's parent, the total weight of tasks being carried (which can be computed directly from the list of carried tasks), a list of actions, \textit{actions required}, that the agent needs to take to transition from the parent node, and the tree level on which the node exists. A \texttt{Node} class was created to encapsulate the state and supplemental information. 
\subsection{Goal State}
% Describe the goal state %
The goal state for the agent is to have no remaining tasks to pick-up or deliver. This is represented in the tree as reaching a node which has no children nodes. Nodes satisfying this goal state are not unique. The optimality of a node is determined by the magnitude of the distance travelled to reach the node. 

\subsection{Actions}
% Describe the possible actions/transitions in your model %
At any given state, an agent is given up to N+M possible transitions, where N represents that number tasks available for pick-up and M represents the number of tasks currently being carried which can be dropped-off. Each of these possible actions will cause the agent to transition to the city of the respective pick-up or drop-off task.\\

Two unique node types were identified : a node where the vehicle has picks up a task in a city, and a node where the vehicle goes directly to a city to drop off a task.To further reduce the number of nodes, the following conditions are checked :

\begin{compactenum}
	\item If the vehicle has a delivery destined for any city along the path from the current city to the target city, the deliveries are all added to the single node.
	\item If a picking up a task would exceed the vehicle's capacity, the node is invalid and is not added to the tree.
	\item If a goal state has already been reached, do not create a node if it's distance travelled exceeds the current best. 
\end{compactenum}

\section{Implementation}
Prior to implementing either search algorithm, a \texttt{Tree} class was created, which established the functions and data structures required to create a tree of \texttt{Node} states. The \texttt{Tree} can be initialized differently, to either generate and store the whole tree immediately or to generate the tree incrementally, depending on the search algorithm being implemented. The former option is not used in our final optimized versions of BFS and A*. The \texttt{Tree} class also has functions to remove nodes, return all nodes at a given level, check the goal condition for a node, and to generate children for a node. 

\subsection{BFS}
% Details of the BFS implementation %
The Breadth First Search (BFS) algorithm determines the absolute optimal pick-up and delivery plan for an agent by searching through all possible paths. To do this, first the entire state tree is generated. Then, starting at the tree's root node and working down level-by-level, each node is evaluated. On every level, the algorithm will first check the distance to root parameter for a node and compare it to the current best distance (initialized as \texttt{ double.MAX\char`_VALUE} such that any path reaching the goal state can trump the default value). Any node with a distance greater than the current best is not added to the tree. If the node's distance to root is lower than the current best, the algorithm checks if the node satisfies the goal condition of having no children. If the node has no children, then it is the new best node and the best distance parameter is updated accordingly. If the node has children, a flag is set to continue the search of remaining nodes on the next tree level. On each level the flag is reset. The algorithm continues checking subsequent levels of the tree until the flag is not reset. Once this condition is met and every node on the level has been explored, the best node is returned. A list of actions required to get to the optimal node is generated by travelling up the tree until the root is found, and storing each node's \textit{actions required} in an ArrayList. Finally, a plan is generated using the agent's starting city and the generated list of actions. This plan is returned and is implemented by the agent. 
\subsection{A*}
% Details of the A* implementation %
The A* algorithm is used along a heuristic that estimates the distance between the current node and a goal node.\\

It goes deeper into the tree by trying first the nodes who, according to the heuristic, are closer to a goal node.\\

Once a goal node is found, the implementation of A* has been made so that it computes the actions necessary to go from the root node to this goal node, and creates a Plan object out of this list of actions.\\

When it comes to the implementation of A*, we made the \texttt{abstract class AstarPlan}, with the method \texttt{abstract double h(Node node)} representing the heuristic. For each A* algorithm (using each a different heuristics), we make a class that inherits from\textsl{} the class AstarPlan and then implement the heuristic. 

\subsection{Heuristic Function}
% Details of the heuristic functions: main idea, optimality, admissibility %
We tried two heuristic functions, represented by the classes \texttt{AstarPlanWithZeroHeuristic} and \texttt{AstarPlanWithMinDistanceHeuristic} (TODO CHECK CORRECT NAME).\\

The class \texttt{AstarPlanWithZeroHeuristic} has a heuristic always returning zero, clearly underestimating the distance from the current node to a goal node. In that sense, the heuristic is \textit{admissible}. The admissibility of the heuristics leads A* to always finding the optimal solution. Therefore, this heuristic is \textit{optimal}. It is however important to note that this heuristic is very inefficient, with a large execution time. (TODO: HOW LARGE)\\

The class \texttt{AstarPlanWithMinDistanceHeuristic} (TODO CHANGE NAME) is the second A* algorithm implemented. Its heuristic considers the minimum amount of distance it had to travel to get to its first task at the beginning. Then, it considers that to deliver each task the vehicle is currently carrying, it has to travel that same distance. It also considers that to pickup and deliver each task it has not picked up yet, it has to travel twice that same distance. The heuristic then returns the "expected distance to travel" varying with the number of carried tasks and the number of tasks left to pick up. This heuristic is not \textit{admissible} since it does not underestimate the distance to a goal node. Therefore, it leads A* to not always finding the optimal solution (This heuristic is hereby not \textit{optimal}). It is however important to note that this heuristic finds a solution much faster than the previous admissible heuristic. (TODO: HOW MUCH QUICKER?) 

\section{Results}

\subsection{Experiment 1: BFS and A* Comparison}
% Compare the two algorithms in terms of: optimality, efficiency, limitations %
% Report the number of tasks for which you can build a plan in less than one minute %


\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %

\subsubsection{Observations}
% Describe the experimental results and the conclusions you inferred from these results %
c
A* can handle more tasks than BFS


\subsection{Experiment 2: Multi-agent Experiments}
% Observations in multi-agent experiments %

\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %

\subsubsection{Observations}
% Describe the experimental results and the conclusions you inferred from these results %

\end{document}