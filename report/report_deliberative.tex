\documentclass[11pt]{article}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage[top=0.8in, bottom=0.8in, left=0.8in, right=0.8in]{geometry}
% add other packages here
\usepackage{courier}
\usepackage{graphicx}
\usepackage{array}
\usepackage{wrapfig}

% Put your group number and names in the author field %
\title{\bf Exercise 3\\ Implementing a deliberative Agent}
\author{Group \textnumero76: Simon Honigmann, Arthur Gassner}

% N.B.: The report should not be longer than 3 pages %

\begin{document}
\maketitle

\section{Model Description}

\subsection{Intermediate States}
% Describe the state representation %
For this exercise, the state representation could be simplified compared to the previous because task information is available to the agents. State was represented by the current city of a given agent, a list of all available tasks, and a list of all tasks currently being carried by the agent. A \texttt{State} class was created to conveniently encode this information. \\

In addition to the information included in the vehicle's state, we added some information to the nodes to reduce the complexity of planning algorithms. This information included: the total distance travelled from the root node, the node's parent, the total weight of tasks being carried (which can be computed directly from the list of carried tasks), a list of actions, \textit{actions required}, that the agent needs to take to transition from the parent node, and the tree level on which the node exists. A \texttt{Node} class was created to encapsulate the state and supplemental information. 
\subsection{Goal State}
% Describe the goal state %
The goal state for the agent is to have no remaining tasks to pick-up or deliver. This is represented in the tree as reaching a node which has no children nodes. Nodes satisfying this goal state are not unique. The optimality of a node is determined by the magnitude of the distance travelled to reach the node. 

\subsection{Actions}
% Describe the possible actions/transitions in your model %
At any given state, an agent is given up to N+M possible transitions, where N represents that number tasks available for pick-up and M represents the number of tasks currently being carried which can be dropped-off. Each of these possible actions will cause the agent to transition to the city of the respective pick-up or drop-off task.\\

In order to reduce the amount of nodes, a given node can transition into three different kinds of new nodes : 

\begin{compactenum}
	\item a node where the vehicle has picked up a task in a City A and delivered a non-zero amount of tasks in that same City A;
	\item a node where the vehicle has picked up a task in a City A and delivered nto task in the City A;                                                                   	\item a node where the vehicle has picked up no task and delivered a non-zero amount of tasks to a City A.\\
\end{compactenum}

On top of these improvements, if the vehicle \textit{has to} pass over a city where it can deliver a task, it does automatically.

\section{Implementation}
Prior to implementing either search algorithm, a \texttt{Tree} class was created, which established the functions and data structures required to create a tree of \texttt{Node} states. The \texttt{Tree} can be initialized differently, to either generate and store the whole tree immediately or to generate the tree incrementally, depending on the search algorithm being implemented. The \texttt{Tree} class also has functions to remove nodes, return all nodes at a given level, check the goal condition for a node, and to generate children for a node. 

\subsection{BFS}
% Details of the BFS implementation %
The Breadth First Search (BFS) algorithm determines the absolute optimal pick-up and delivery plan for an agent by searching through all possible paths. To do this, the tree is incrementally generated. Then, starting at the tree's root node and working down level-by-level, each node is evaluated. As nodes are added to the working list of nodes, they are ordered based on their distance from the root. Nodes are evaluated against the goal condition, then removed from the working list. A list of actions required to get to the optimal node is generated by travelling up the tree until the root is found, and storing each node's \textit{actions required} in an ArrayList. Finally, a plan is generated using the agent's starting city and the generated list of actions. This plan is returned and is implemented by the agent. 
\subsection{A*}
% Details of the A* implementation %
The A* algorithm is used along a heuristic that estimates the distance between the current node and a goal node.\\

It goes deeper into the tree by trying first the nodes who, according to the heuristic, are closer to a goal node.\\

Once a goal node is found, the implementation of A* has been made so that it computes the actions necessary to go from the root node to this goal node, and creates a Plan object out of this list of actions.\\

When it comes to the implementation of A*, we made the \texttt{abstract class AstarPlan}, with the method \texttt{abstract double h(Node node)} representing the heuristic. For each A* algorithm (using each a different heuristics), we make a class that inherits from\textsl{} the class AstarPlan and then implement the heuristic. 

\subsection{Heuristic Function}
% Details of the heuristic functions: main idea, optimality, admissibility %
We tried two heuristic functions, represented by the classes \texttt{AstarPlanWithZeroHeuristic} and \texttt{AstarPlanWithMinDistanceHeuristic}.\\

The class \texttt{AstarPlanWithZeroHeuristic} has a heuristic always returning zero, clearly underestimating the distance from the current node to a goal node. In that sense, the heuristic is \textit{admissible}. The admissibility of the heuristics leads A* to always finding the optimal solution. Therefore, this heuristic is \textit{optimal}. It is however important to note that this heuristic is very inefficient, with a large execution time (10.5 seconds for 6 tasks in Switzerland).\\

The class \texttt{AstarPlanWithMinDistanceHeuristic} is the second A* algorithm implemented. Its heuristic considers the minimum amount of distance it had to travel to get to its first task at the beginning. Then, it considers that to deliver each task the vehicle is currently carrying, it has to travel that same distance. It also considers that to pick-up and deliver each task it has not picked up yet, it has to travel twice that same distance. The heuristic then returns the "expected distance to travel" varying with the number of carried tasks and the number of tasks left to pick up. This heuristic is not \textit{admissible} since it does not underestimate the distance to a goal node. Therefore, it leads A* to not always finding the optimal solution (This heuristic is hereby not \textit{optimal}). It is however important to note that this heuristic finds a solution much faster than the previous admissible heuristic (0.5 second for 6 tasks in Switzerland).

\section{Results}
Each search algorithms was thoroughly tested to ensure its robustness and optimality. Each search function was run on all 4 provided topologies. Additionally, different starting seeds were attempted to ensure they performed consistently across different initial conditions. Generated plans were compared between the BFS and the ZeroHeuristic to ensure they were identical, as both should return the same unique optimal solution. The following experiments present performance and efficiency metrics for each of the algorithms with several different seed values. 
\subsection{Experiment 1: BFS and A* Comparison}
% Compare the two algorithms in terms of: optimality, efficiency, limitations %
% Report the number of tasks for which you can build a plan in less than one minute %
Our BFS algorithm was compared against both A* search algorithms using for single agents operating in the Swiss topology and different random seeds. All agents start in Lausanne. 

\begin{table}[]
	\begin{tabular}{|c|c|c|c|}
		\hline
		Seed & Algorithm & Distance Travelled  for 6 Tasks (km) & Computation Time for 6 Tasks (s) \\ \hline
		\multirow{3}{*}{23456} & BFS & 1380 & 8.7 \\ \cline{2-4} 
		& A* Zero Heuristic & 1380 & 10.7 \\ \cline{2-4} 
		& A* Minimum Distance & 1460 & 0.7 \\ \hline
		\multirow{3}{*}{23457} & BFS & 1510 & 10.7 \\ \cline{2-4} 
		& A* Zero Heuristic & 1510 & 63 \\ \cline{2-4} 
		& A* Minimum Distance & 1590 & 0.5 \\ \hline
		\multirow{3}{*}{23458} & BFS & 910 & 15.5 \\ \cline{2-4} 
		& A* Zero Heuristic & 910 & 16 \\ \cline{2-4} 
		& A* Minimum Distance & 910 & 0.5 \\ \hline
		\multirow{3}{*}{Average} & BFS & 1266.7 & 11.6 \\ \cline{2-4} 
		& A* Zero Heuristic & 1266.7 & 29.9 \\ \cline{2-4} 
		& A* Minimum Distance & 1320.0 & 0.6 \\ \hline
	\end{tabular}
\end{table}

As is apparent in the above table, the Zero Heuristic algorithm ends up being the slowest due to the poor choice of heuristic, and potentially the increased optimization efforts for BFS, trying to manage 8 tasks. Both BFS and A* with the Zero Heuristic return the same, optimal path. 

A* with the Minimum Distance heuristic performed formidably as well. While it's decisions were not always optimal, it's selected plans were within 4\% of the distance travelled of the optimal solution with a considerable 20x decrease in computation speed compared to BFS. A* with the Minimum Distance heuristic also trumped the other algorithms in its capacity to handle tasks. In under 1 minute, BFS could handle 6 tasks reliably, A* with Zero heuristic could handle 10 tasks, and A* with Minimum Distance heuristic could handle about 53 tasks. 

\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %

\subsubsection{Observations}
% Describe the experimental results and the conclusions you inferred from these results %
c
A* can handle more tasks than BFS


\subsection{Experiment 2: Multi-agent Experiments}
% Observations in multi-agent experiments %

\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %

\subsubsection{Observations}
% Describe the experimental results and the conclusions you inferred from these results %

\end{document}